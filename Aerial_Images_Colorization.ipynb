{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pengyu-gis/Historical-Aerial-Photos/blob/main/Aerial_Images_Colorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7jQb8ZwcHQw"
      },
      "source": [
        "### **<font color='blue'> Artistic Colorizer </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "663IVxfrpIAb"
      },
      "source": [
        "#◢ DeOldify - Colorize your own photos!\n",
        "\n",
        "####**Credits:**\n",
        "\n",
        "Special thanks to:\n",
        "\n",
        "Matt Robinson and María Benavente for pioneering the DeOldify image colab notebook.  \n",
        "\n",
        "Dana Kelley for doing things, breaking stuff & having an opinion on everything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjPqTBNoohK9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#◢ Verify Correct Runtime Settings\n",
        "\n",
        "**<font color='#FF000'> IMPORTANT </font>**\n",
        "\n",
        "In the \"Runtime\" menu for the notebook window, select \"Change runtime type.\" Ensure that the following are selected:\n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaEJBGDlptEo"
      },
      "source": [
        "#◢ Git clone and install DeOldify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T-svuHytJ-8",
        "outputId": "e8a9094a-3285-4adf-8531-fc33f0dd492d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeOldify'...\n",
            "remote: Enumerating objects: 2615, done.\u001b[K\n",
            "remote: Counting objects: 100% (269/269), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 2615 (delta 91), reused 204 (delta 71), pack-reused 2346 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2615/2615), 69.71 MiB | 11.28 MiB/s, done.\n",
            "Resolving deltas: 100% (1174/1174), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jantic/DeOldify.git DeOldify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xDZjHyvrcHQz",
        "outputId": "7ef420ba-be81-44e9-9e68-f84a202ae462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeOldify\n"
          ]
        }
      ],
      "source": [
        "!cd DeOldify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDFjbNxaadNK"
      },
      "source": [
        "#◢ Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "00_GcC_trpdE"
      },
      "outputs": [],
      "source": [
        "#NOTE:  This must be the first call in order to work properly!\n",
        "from deoldify import device\n",
        "from deoldify.device_id import DeviceId\n",
        "#choices:  CPU, GPU0...GPU7\n",
        "device.set(device=DeviceId.GPU0)\n",
        "\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print('GPU not available.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lsx7xCXNSVt6"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements-colab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsJa69CMwj3l",
        "outputId": "1f1a8b31-391e-40a3-9fab-b8971ce7e27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumExpr defaulting to 2 threads.\n"
          ]
        }
      ],
      "source": [
        "import fastai\n",
        "from deoldify.visualize import *\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ee5WH1jrcHQ0",
        "outputId": "a5413f6e-4e2f-4b3b-94ab-b99257068b51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n",
            "--2024-10-06 20:28:48--  https://data.deepai.org/deoldify/ColorizeArtistic_gen.pth\n",
            "Resolving data.deepai.org (data.deepai.org)... 169.150.249.167, 2400:52e0:1a01::1108:1\n",
            "Connecting to data.deepai.org (data.deepai.org)|169.150.249.167|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 255144681 (243M) [application/octet-stream]\n",
            "Saving to: ‘./models/ColorizeArtistic_gen.pth’\n",
            "\n",
            "./models/ColorizeAr 100%[===================>] 243.32M  4.97MB/s    in 49s     \n",
            "\n",
            "2024-10-06 20:29:38 (4.92 MB/s) - ‘./models/ColorizeArtistic_gen.pth’ saved [255144681/255144681]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir 'models'\n",
        "!wget https://data.deepai.org/deoldify/ColorizeArtistic_gen.pth -O ./models/ColorizeArtistic_gen.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzHVnegp21hC",
        "outputId": "72b877a0-7536-4b14-970d-1e7233f1ffe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 171MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "/content/DeOldify/fastai/basic_train.py:322: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(tmp_file)\n",
            "/content/DeOldify/fastai/basic_train.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(source, map_location=device)\n"
          ]
        }
      ],
      "source": [
        "colorizer = get_image_colorizer(artistic=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDFjbNxaadNJ"
      },
      "source": [
        "#◢ Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5K8oGJYcHQ1"
      },
      "source": [
        "### source_url\n",
        "Type in a url to a direct link of an image.  Usually that means they'll end in .png, .jpg, etc. NOTE: If you want to use your own image, upload it first to a site like Imgur.\n",
        "\n",
        "### render_factor\n",
        "The default value of 35 has been carefully chosen and should work -ok- for most scenarios (but probably won't be the -best-). This determines resolution at which the color portion of the image is rendered. Lower resolution will render faster, and colors also tend to look more vibrant. Older and lower quality images in particular will generally benefit by lowering the render factor. Higher render factors are often better for higher quality images, but the colors may get slightly washed out.\n",
        "\n",
        "### watermarked\n",
        "Selected by default, this places a watermark icon of a palette at the bottom left corner of the image.  This is intended to be a standard way to convey to others viewing the image that it is colorized by AI. We want to help promote this as a standard, especially as the technology continues to improve and the distinction between real and fake becomes harder to discern. This palette watermark practice was initiated and lead by the company MyHeritage in the MyHeritage In Color feature (which uses a newer version of DeOldify than what you're using here).\n",
        "\n",
        "#### How to Download a Copy\n",
        "Simply right click on the displayed image and click \"Save image as...\"!\n",
        "\n",
        "## Pro Tips\n",
        "\n",
        "You can evaluate how well the image is rendered at each render_factor by using the code at the bottom (that cell under \"See how well render_factor values perform on a frame here\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUQrbSYipiJn"
      },
      "source": [
        "#◢ Colorize!!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "TzgDnxUWiFh-",
        "outputId": "d7dd15c4-48a6-403a-fab5-123d847cd213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.8.30)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.1.4)\n",
            "Downloading rasterio-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio as rio\n",
        "import numpy as np\n",
        "from rasterio.plot import reshape_as_image, reshape_as_raster\n",
        "from PIL import Image\n",
        "\n",
        "# Load the TIFF file using rasterio\n",
        "tiff_input_path = '/content/Clip1_0087_x_24.tif'\n",
        "with rio.open(tiff_input_path) as src:\n",
        "    meta = src.meta.copy()  # Copy the metadata (including CRS)\n",
        "    image_array = src.read()  # Read the image as a numpy array\n",
        "\n",
        "    # Convert the image to RGB (assuming the first 3 bands correspond to RGB channels)\n",
        "    if image_array.shape[0] > 3:\n",
        "        image_array_rgb = image_array[:3, :, :]  # Use only the first three bands\n",
        "    else:\n",
        "        image_array_rgb = image_array  # If already 3-channel\n",
        "\n",
        "    # Reshape as image for processing (channels-last format)\n",
        "    image_rgb = reshape_as_image(image_array_rgb)\n",
        "\n",
        "    # Use DeOldify to colorize the image\n",
        "    # Convert the numpy array to a PIL Image\n",
        "    image_rgb = Image.fromarray(image_rgb)\n",
        "\n",
        "    # Save the image\n",
        "    image_rgb.save('temp.png')\n",
        "    #The get_transformed_image function expects a path not a PIL Image\n",
        "    # Pass the path to the saved image to colorizer.get_transformed_image\n",
        "    colorized_image = colorizer.get_transformed_image('temp.png', render_factor=35, watermarked=True)\n",
        "\n",
        "    # Convert the colorized image back to raster format (channels-first)\n",
        "    colorized_image_array = np.array(colorized_image)\n",
        "\n",
        "    # Ensure that the array is in (bands, height, width) format\n",
        "    colorized_image_raster = colorized_image_array.transpose(2, 0, 1)\n",
        "\n",
        "# Update metadata for the output TIFF (ensure 3 bands)\n",
        "meta.update({\n",
        "    \"count\": 3,  # Number of bands (RGB)\n",
        "    \"dtype\": 'uint8',  # Data type should match the output image type\n",
        "    \"height\": colorized_image_raster.shape[1],  # Update height to match the colorized image\n",
        "    \"width\": colorized_image_raster.shape[2]  # Update width to match the colorized image\n",
        "})\n",
        "\n",
        "# Save the colorized TIFF while preserving CRS and metadata\n",
        "tiff_output_path = 'output_image_test1.tif'\n",
        "with rio.open(tiff_output_path, 'w', **meta) as dst:\n",
        "    dst.write(colorized_image_raster)\n",
        "\n",
        "print(f\"Colorized image saved at {tiff_output_path}\")\n"
      ],
      "metadata": {
        "id": "iyW_nbzHkg1F",
        "outputId": "ebef1a38-9050-4503-d72e-03fac88bb19c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colorized image saved at output_image_test1.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Ycv_Y9xAHp"
      },
      "source": [
        "---\n",
        "#⚙ Recommended image sources\n",
        "* [/r/TheWayWeWere](https://www.reddit.com/r/TheWayWeWere/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ImageColorizerColab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}